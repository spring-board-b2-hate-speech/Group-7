{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8faaffe",
   "metadata": {},
   "source": [
    "# Evaluating ML Models after Hypertunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f09d8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# File paths\n",
    "train_file = r\"C:\\Users\\prits\\Downloads\\Data\\clean_ghc_train.csv\"\n",
    "# Load CSV files into pandas DataFrames\n",
    "train_df = pd.read_csv(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709b0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Drop rows with NaN in 'text' column\n",
    "train_df = train_df.dropna(subset=['text'])\n",
    "\n",
    "# Step 2: Split the data into X (features) and y (labels)\n",
    "X = train_df['text']\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e76b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "# Initialize TfidfVectorizer with adjusted parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform X_train (text data) using TfidfVectorizer\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test using the fitted TfidfVectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Balance the training data \n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled= ros.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf8b278",
   "metadata": {},
   "source": [
    "# HYPERTUNNING OF DIFFERENT ML MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0219810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "def train_best_model(X_resampled, y_resampled):\n",
    "    # Define the parameter grids for each model\n",
    "    param_grids = {\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(max_iter=1000),\n",
    "            'params': {\n",
    "                'C': [0.1, 10],\n",
    "                'solver': ['liblinear'],\n",
    "                'penalty': ['l2']\n",
    "            }\n",
    "        },\n",
    "        'SVC': {\n",
    "            'model': SVC(),\n",
    "            'params': {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'gamma': ['scale', 'auto'],\n",
    "                'kernel': ['rbf']\n",
    "            }\n",
    "        },\n",
    "        'MultinomialNB': {\n",
    "            'model': MultinomialNB(),\n",
    "            'params': {\n",
    "                'alpha': [0.01, 0.1, 0.5, 1.0]\n",
    "            }\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'model': RandomForestClassifier(),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'model': GradientBoostingClassifier(),\n",
    "            'params': {\n",
    "                'n_estimators': [100],\n",
    "                'learning_rate': [0.1, 0.5],\n",
    "                'max_depth': [3, 5,]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    best_models = {}\n",
    "  \n",
    "    \n",
    "    # Perform hyperparameter tuning\n",
    "    for name, cfg in param_grids.items():\n",
    "        grid_search = GridSearchCV(cfg['model'], cfg['params'], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        best_models[name] = grid_search.best_estimator_\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "# Example usage\n",
    "best_models = train_best_model(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9944fe4",
   "metadata": {},
   "source": [
    "# Printing the accuracy,recall and confusion matrix of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfcae2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Results for LogisticRegression =====\n",
      "Accuracy: 0.821\n",
      "Recall: 0.542\n",
      "Confusion Matrix:\n",
      "[[3274  526]\n",
      " [ 254  301]]\n",
      "\n",
      "\n",
      "===== Results for SVC =====\n",
      "Accuracy: 0.886\n",
      "Recall: 0.213\n",
      "Confusion Matrix:\n",
      "[[3742   58]\n",
      " [ 437  118]]\n",
      "\n",
      "\n",
      "===== Results for MultinomialNB =====\n",
      "Accuracy: 0.754\n",
      "Recall: 0.573\n",
      "Confusion Matrix:\n",
      "[[2966  834]\n",
      " [ 237  318]]\n",
      "\n",
      "\n",
      "===== Results for RandomForest =====\n",
      "Accuracy: 0.878\n",
      "Recall: 0.187\n",
      "Confusion Matrix:\n",
      "[[3721   79]\n",
      " [ 451  104]]\n",
      "\n",
      "\n",
      "===== Results for GradientBoosting =====\n",
      "Accuracy: 0.850\n",
      "Recall: 0.501\n",
      "Confusion Matrix:\n",
      "[[3422  378]\n",
      " [ 277  278]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "def predict_and_evaluate(best_models, X_test_tfidf, y_test):\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in best_models.items():\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'recall': recall,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_results(results):\n",
    "    for name, metrics in results.items():\n",
    "        accuracy = metrics['accuracy']\n",
    "        recall = metrics['recall']\n",
    "        cm = metrics['confusion_matrix']\n",
    "        \n",
    "        print(f'===== Results for {name} =====')\n",
    "        print(f'Accuracy: {accuracy:.3f}')\n",
    "        print(f'Recall: {recall:.3f}')\n",
    "        print('Confusion Matrix:')\n",
    "        print(cm)\n",
    "        print('\\n')\n",
    "\n",
    "# Example usage\n",
    "results = predict_and_evaluate(best_models, X_test_tfidf, y_test)\n",
    "print_results(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10bd342",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be64a16f",
   "metadata": {},
   "source": [
    "Gradient Boosting with 85% of accuracy is Performing best compare to all other different Models.\n",
    "There are models such as Random forest and SVM that have greater accuracy than GB but they are unable to classify the minority class at all,they are biased toward majority class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
