{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193cffde-756b-4ae5-a1ec-b439626047fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# File paths\n",
    "train_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_train.csv\"\n",
    "test_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_test.csv\"\n",
    "\n",
    "# Load CSV files into pandas DataFrames\n",
    "train_df = pd.read_csv(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f80d04a-158f-4ac0-a909-b7acb99c544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Drop rows with NaN in 'text' column\n",
    "train_df = train_df.dropna(subset=['text'])\n",
    "\n",
    "# Step 2: Split the data into X (features) and y (labels)\n",
    "X = train_df['text']\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2865d1a-376f-4e78-bc3b-eefacce16d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "\n",
    "# Initialize TfidfVectorizer with adjusted parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform X_train (text data) using TfidfVectorizer\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform X_test using the fitted TfidfVectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Balance the training data \n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled= ros.fit_resample(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8699001-0697-4ef8-ad8f-6d288f072a6b",
   "metadata": {},
   "source": [
    "HYPERTUNING OF GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5d4bb3-0e02-47ac-ac72-b3a955925780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def train_best_gradient_boosting(X_resampled, y_resampled):\n",
    "    # Define the parameter grid for Gradient Boosting\n",
    "    param_grid = {\n",
    "        'n_estimators': [100],\n",
    "        'learning_rate': [0.1, 0.5],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "    \n",
    "    # Create a Gradient Boosting model\n",
    "    model = GradientBoostingClassifier()\n",
    "    \n",
    "    # Perform hyperparameter tuning using GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Get the best Gradient Boosting model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Example usage\n",
    "best_gradient_boosting_model = train_best_gradient_boosting(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ef8e21-63e7-4482-b01e-cdd7e8dc262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Results for GradientBoosting =====\n",
      "Accuracy: 0.855\n",
      "Recall: 0.540\n",
      "Confusion Matrix:\n",
      "[[3436  389]\n",
      " [ 244  286]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "\n",
    "def predict_and_evaluate_gradient_boosting(best_gradient_boosting_model, X_test_tfidf, y_test):\n",
    "    results = {}\n",
    "    \n",
    "    # Predict using the Gradient Boosting model\n",
    "    y_pred = best_gradient_boosting_model.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results['GradientBoosting'] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_gradient_boosting_results(results):\n",
    "    for name, metrics in results.items():\n",
    "        accuracy = metrics['accuracy']\n",
    "        recall = metrics['recall']\n",
    "        cm = metrics['confusion_matrix']\n",
    "        \n",
    "        print(f'===== Results for {name} =====')\n",
    "        print(f'Accuracy: {accuracy:.3f}')\n",
    "        print(f'Recall: {recall:.3f}')\n",
    "        print('Confusion Matrix:')\n",
    "        print(cm)\n",
    "        print('\\n')\n",
    "\n",
    "# Example usage\n",
    "gradient_boosting_results = predict_and_evaluate_gradient_boosting(best_gradient_boosting_model, X_test_tfidf, y_test)\n",
    "print_gradient_boosting_results(gradient_boosting_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab01a6a-d794-4967-964d-f43854116b77",
   "metadata": {},
   "source": [
    "HYPERTUNING OF LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75335d50-55c8-4cdc-8740-d5eda330187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_best_logistic_regression(X_resampled, y_resampled):\n",
    "    # Define the parameter grid for Logistic Regression\n",
    "    param_grid = {\n",
    "        'C': [0.1, 10],\n",
    "        'solver': ['liblinear'],\n",
    "        'penalty': ['l2']\n",
    "    }\n",
    "    \n",
    "    # Create a Logistic Regression model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    # Perform hyperparameter tuning using GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Get the best Logistic Regression model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Example usage\n",
    "best_logistic_regression_model = train_best_logistic_regression(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93237fe7-4e79-4e4f-91fd-5237f4535af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Results for LogisticRegression =====\n",
      "Accuracy: 0.826\n",
      "Recall: 0.555\n",
      "Confusion Matrix:\n",
      "[[3304  521]\n",
      " [ 236  294]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "\n",
    "def predict_and_evaluate_logistic_regression(best_logistic_regression_model, X_test_tfidf, y_test):\n",
    "    results = {}\n",
    "    \n",
    "    # Predict using the Logistic Regression model\n",
    "    y_pred = best_logistic_regression_model.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results['LogisticRegression'] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_logistic_regression_results(results):\n",
    "    for name, metrics in results.items():\n",
    "        accuracy = metrics['accuracy']\n",
    "        recall = metrics['recall']\n",
    "        cm = metrics['confusion_matrix']\n",
    "        \n",
    "        print(f'===== Results for {name} =====')\n",
    "        print(f'Accuracy: {accuracy:.3f}')\n",
    "        print(f'Recall: {recall:.3f}')\n",
    "        print('Confusion Matrix:')\n",
    "        print(cm)\n",
    "        print('\\n')\n",
    "\n",
    "# Example usage\n",
    "logistic_regression_results = predict_and_evaluate_logistic_regression(best_logistic_regression_model, X_test_tfidf, y_test)\n",
    "print_logistic_regression_results(logistic_regression_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e58e662-c31c-4797-9bde-aa03fca88439",
   "metadata": {},
   "source": [
    "HYPERTUNING OF MULTINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53b87fe1-41da-43e7-ba90-54dd615cc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def train_best_multinomial_nb(X_resampled, y_resampled):\n",
    "    # Define the parameter grid for Multinomial Naive Bayes\n",
    "    param_grid = {\n",
    "        'alpha': [0.01, 0.1, 0.5, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Create a Multinomial Naive Bayes model\n",
    "    model = MultinomialNB()\n",
    "    \n",
    "    # Perform hyperparameter tuning using GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Get the best Multinomial Naive Bayes model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "# Example usage\n",
    "best_multinomial_nb_model = train_best_multinomial_nb(X_resampled, y_resampled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039e1c4f-bc8c-42b5-a422-aec7aab6d254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Results for MultinomialNB =====\n",
      "Accuracy: 0.763\n",
      "Recall: 0.577\n",
      "Confusion Matrix:\n",
      "[[3019  806]\n",
      " [ 224  306]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "\n",
    "def predict_and_evaluate_naive_bayes(best_multinomial_nb_model, X_test_tfidf, y_test):\n",
    "    results = {}\n",
    "    \n",
    "    # Predict using the Multinomial Naive Bayes model\n",
    "    y_pred = best_multinomial_nb_model.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results['MultinomialNB'] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_naive_bayes_results(results):\n",
    "    for name, metrics in results.items():\n",
    "        accuracy = metrics['accuracy']\n",
    "        recall = metrics['recall']\n",
    "        cm = metrics['confusion_matrix']\n",
    "        \n",
    "        print(f'===== Results for {name} =====')\n",
    "        print(f'Accuracy: {accuracy:.3f}')\n",
    "        print(f'Recall: {recall:.3f}')\n",
    "        print('Confusion Matrix:')\n",
    "        print(cm)\n",
    "        print('\\n')\n",
    "\n",
    "# Example usage\n",
    "naive_bayes_results = predict_and_evaluate_naive_bayes(best_multinomial_nb_model, X_test_tfidf, y_test)\n",
    "print_naive_bayes_results(naive_bayes_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe6742e-76a1-4d51-a346-f86203ec5804",
   "metadata": {},
   "source": [
    "HYPERTUNING OF RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f1508bc-f8bc-4520-8292-11c8922f93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_best_random_forest(X_resampled, y_resampled):\n",
    "    # Define the parameter grid for RandomForestClassifier\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    \n",
    "    # Create a RandomForestClassifier model\n",
    "    model = RandomForestClassifier()\n",
    "    \n",
    "    # Perform hyperparameter tuning using GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Get the best RandomForestClassifier model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "# Example usage\n",
    "best_random_forest_model = train_best_random_forest(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "516dd7ad-566e-4f35-89b3-4757a5b02df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Results for RandomForest =====\n",
      "Accuracy: 0.893\n",
      "Recall: 0.247\n",
      "Confusion Matrix:\n",
      "[[3757   68]\n",
      " [ 399  131]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "\n",
    "def predict_and_evaluate_random_forest(best_random_forest_model, X_test_tfidf, y_test):\n",
    "    results = {}\n",
    "    \n",
    "    # Predict using the RandomForestClassifier model\n",
    "    y_pred = best_random_forest_model.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results['RandomForest'] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_random_forest_results(results):\n",
    "    for name, metrics in results.items():\n",
    "        accuracy = metrics['accuracy']\n",
    "        recall = metrics['recall']\n",
    "        cm = metrics['confusion_matrix']\n",
    "        \n",
    "        print(f'===== Results for {name} =====')\n",
    "        print(f'Accuracy: {accuracy:.3f}')\n",
    "        print(f'Recall: {recall:.3f}')\n",
    "        print('Confusion Matrix:')\n",
    "        print(cm)\n",
    "        print('\\n')\n",
    "\n",
    "# Example usage\n",
    "random_forest_results = predict_and_evaluate_random_forest(best_random_forest_model, X_test_tfidf, y_test)\n",
    "print_random_forest_results(random_forest_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109248b2-b6d1-418b-b2e4-25b1cea254c1",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "Gradient Boosting with 85% of accuracy is Performing best compare to all other different Models. There are models such as Random forest and SVM that have greater accuracy as well as GB but they are unable to classify the minority class at all,they are biased toward majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7945b1a-0511-4d6a-8a19-dacb08110e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
