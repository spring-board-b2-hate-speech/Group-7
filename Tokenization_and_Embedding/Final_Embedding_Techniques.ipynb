{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f3c80a-905b-4873-9845-7281c28c0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Python package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f1744f-5dc5-4566-9db4-ca221dc3331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_file = r'C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_train.csv'\n",
    "test_file = r'C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_test.csv'\n",
    "# Load CSV files into pandas DataFrames\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a59bad-a5dc-4f45-af92-460e4385c6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  hd  cv  vo label\n",
      "0      He most likely converted to islam due to his n...   0   0   0     h\n",
      "1      So Ford lied about being a psychologist. Recor...   0   0   0     h\n",
      "2      Jobs. Education. Ending abuse of Nation. Calif...   0   0   0    nh\n",
      "3      I share a lot of your values, & like many who ...   0   0   0     h\n",
      "4      I am so ready to get back to blogging!  recipe...   0   0   0    nh\n",
      "...                                                  ...  ..  ..  ..   ...\n",
      "22031  I'm a fan of western civilization, and one bed...   0   0   0     h\n",
      "22032  Or ... is she saying that Muslims don't know h...   0   0   0     h\n",
      "22033  Thank you to all my followers that follow me e...   0   0   0     h\n",
      "22034                                  Wednesday music.    0   0   0    nh\n",
      "22035                   This is a really Big Surprise!     0   0   0     h\n",
      "\n",
      "[22036 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f05e9197-2e68-4583-92b0-1e10200bec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b638f9-8b70-46a8-8e94-1fbf5d16d9d4",
   "metadata": {},
   "source": [
    "OneHotEncoding:One hot encoding is a technique that we use to represent categorical variables as numerical values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45fbe17-5a66-4e4a-9f83-2d546f64dbc9",
   "metadata": {},
   "source": [
    "One hot encoding is a technique used in machine learning and data processing to represent categorical variables as binary vectors. Each category is converted into a binary vector where only one bit is '1' and all others are '0'. This encoding is useful for algorithms that cannot work directly with categorical data and require numerical input, such as neural networks and decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e79013-2071-4348-8abe-f358e5441222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  hd  cv  vo label\n",
      "0  He most likely converted to islam due to his n...   0   0   0     h\n",
      "1  So Ford lied about being a psychologist. Recor...   0   0   0     h\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22036 entries, 0 to 22035\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    22013 non-null  object\n",
      " 1   hd      22036 non-null  int64 \n",
      " 2   cv      22036 non-null  int64 \n",
      " 3   vo      22036 non-null  int64 \n",
      " 4   label   22036 non-null  object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 860.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "print(train_df.head(2), sep = \" \")\n",
    "train_df.info()\n",
    "train_df['text'] = train_df['label'].astype(str)\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(train_df[['label']])\n",
    "# Converting the encoded data into an array\n",
    "encoded_array = encoded_data.toarray()\n",
    "\n",
    "# Print the encoded data (this will show the transformed categorical data)\n",
    "encoded_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b704923c-5689-4cef-8953-86420d88a32e",
   "metadata": {},
   "source": [
    "DRAWBACKS:\n",
    "1.High Dimensionality, \n",
    "2.Curse of Dimensionality, \n",
    "3.Increased Memory Usage, \n",
    "4.Loss of Semantics, \n",
    "5.Handling New Categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89394c-14fd-43ed-8f60-6a132eed1be6",
   "metadata": {},
   "source": [
    "Label Encoding : Label Encoding is a technique that is used to convert categorical columns into numerical ones so that they can be fitted by machine learning models which only take numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ef254d0-b2d8-469f-acdc-552e6e37b062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        text  hd  cv  vo  label\n",
      "0       6303   0   0   0      0\n",
      "1      14284   0   0   0      0\n",
      "2       9980   0   0   0      1\n",
      "3       7984   0   0   0      0\n",
      "4       7127   0   0   0      1\n",
      "...      ...  ..  ..  ..    ...\n",
      "22031   8436   0   0   0      0\n",
      "22032  12664   0   0   0      0\n",
      "22033  15140   0   0   0      0\n",
      "22034  18185   0   0   0      1\n",
      "22035  16886   0   0   0      0\n",
      "\n",
      "[22036 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to each column\n",
    "encoded_data = train_df.apply(encoder.fit_transform)\n",
    "\n",
    "# Print the encoded data\n",
    "print(encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2f970a5-6bd5-41d2-b2d9-16c94e177812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60\n",
      "Precision: 0.59\n",
      "Recall: 0.60\n",
      "F1 Score: 0.60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to each column that is categorical\n",
    "categorical_columns = ['text', 'label']\n",
    "for col in categorical_columns:\n",
    "    train_df[col] = encoder.fit_transform(train_df[col])\n",
    "x = train_df['text'].values\n",
    "y = train_df['label'].values\n",
    "# Step 2: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "# Reshape X_train and X_test if needed\n",
    "X_train = X_train.reshape(-1, 1)  # Example reshape for X_train, adjust as per your data structure\n",
    "X_test = X_test.reshape(-1, 1)    # Example reshape for X_test, adjust as per your data structure\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04040b6e-a1a7-474f-8c68-09ba22cb9a7a",
   "metadata": {},
   "source": [
    "DRAWBACKS:\n",
    "1.Low Accuracy, \n",
    "2.Handling New Categories, \n",
    "3.Difficulty in Interpretation, \n",
    "4.Impact on Machine Learning Algorithms, \n",
    "5.Limited Expressiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57323369-35d3-4a84-8080-34b80ed7f36d",
   "metadata": {},
   "source": [
    "TF-IDF stands for Term Frequency Inverse Document Frequency of records. It can be defined as the calculation of how relevant a word in a series or corpus is to a text. The meaning increases proportionally to the number of times in the text a word appears but is compensated by the word frequency in the corpus (data-set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf107b93-4b95-49a2-8f1a-bd15e1fde8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2046)\t0.1734177961047654\n",
      "  (0, 2865)\t0.22841937159965145\n",
      "  (0, 2578)\t0.30733769204673606\n",
      "  (0, 4531)\t0.18473798911782097\n",
      "  (0, 2318)\t0.2702851777430834\n",
      "  (0, 1359)\t0.2997086476336335\n",
      "  (0, 2103)\t0.1901106961782535\n",
      "  (0, 2943)\t0.32490862562353595\n",
      "  (0, 465)\t0.21267129484836328\n",
      "  (0, 1748)\t0.12510579599746863\n",
      "  (0, 2319)\t0.310942083693846\n",
      "  (0, 1291)\t0.3916265464291196\n",
      "  (0, 2890)\t0.38341645065029467\n",
      "  (0, 4803)\t0.16319984302244103\n",
      "  (1, 4531)\t0.10000016703543584\n",
      "  (1, 465)\t0.23024138251191123\n",
      "  (1, 4803)\t0.1766827888550042\n",
      "  (1, 4100)\t0.18307056508523645\n",
      "  (1, 1754)\t0.3528720966462922\n",
      "  (1, 2569)\t0.3855430418863006\n",
      "  (1, 87)\t0.1856812604640436\n",
      "  (1, 3619)\t0.37042263776643486\n",
      "  (1, 3915)\t0.3305290824563357\n",
      "  (1, 3980)\t0.23116647920525749\n",
      "  (1, 2395)\t0.18255100990630585\n",
      "  :\t:\n",
      "  (22010, 1735)\t0.16953493028860667\n",
      "  (22010, 1014)\t0.13377703215886275\n",
      "  (22010, 469)\t0.13888417452374757\n",
      "  (22010, 2516)\t0.16442055537006586\n",
      "  (22010, 673)\t0.18965588430824487\n",
      "  (22010, 3178)\t0.14529870883297333\n",
      "  (22010, 2571)\t0.13629569947665954\n",
      "  (22010, 4449)\t0.14756231649844395\n",
      "  (22010, 1732)\t0.1458458101683981\n",
      "  (22010, 2108)\t0.29542157392039464\n",
      "  (22010, 488)\t0.13518526918547383\n",
      "  (22010, 1312)\t0.16653148913790927\n",
      "  (22010, 4701)\t0.14543437315220867\n",
      "  (22010, 169)\t0.15897915591698\n",
      "  (22010, 2324)\t0.2103944799644575\n",
      "  (22010, 2227)\t0.16653148913790927\n",
      "  (22010, 3096)\t0.19386618270983116\n",
      "  (22010, 560)\t0.2103944799644575\n",
      "  (22011, 2902)\t0.6330409866082333\n",
      "  (22011, 4827)\t0.7741182786073938\n",
      "  (22012, 2316)\t0.21409224684837624\n",
      "  (22012, 3602)\t0.4404926351841811\n",
      "  (22012, 4479)\t0.2659560679247386\n",
      "  (22012, 496)\t0.4900711405015668\n",
      "  (22012, 4336)\t0.6702450263667873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_df.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def tfidf_embedding(text):\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    embeddings = vectorizer.fit_transform(text)\n",
    "    return embeddings\n",
    "\n",
    "text = train_df['text'].values\n",
    "embeddings_tfidf = tfidf_embedding(text)\n",
    "print(embeddings_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fe45d81-7e3d-4e58-ac3f-38ed3cacb6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9163\n",
      "Precision: 0.8396\n",
      "Recall: 0.9163\n",
      "F1 Score: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHARGAVI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Step 1: TF-IDF Encoding\n",
    "def tfidf_embedding(text):\n",
    "    vectorizer = TfidfVectorizer(max_features=6000)\n",
    "    embeddings = vectorizer.fit_transform(text)\n",
    "    return embeddings\n",
    "\n",
    "text = train_df['text'].values\n",
    "label = train_df['hd'].values\n",
    "\n",
    "embeddings_tfidf = tfidf_embedding(text)\n",
    "\n",
    "# Step 2: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings_tfidf, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predictions and Evaluation\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9aaec0-8aac-4f72-bf5a-974909104b8a",
   "metadata": {},
   "source": [
    "ADVANTAGES:\n",
    "1.High Accuracy,\n",
    "2.Dimensionality Reduction,\n",
    "3.Semantic Representation,\n",
    "4.Contextual Information,\n",
    "5.Natural Language Understanding,\n",
    "6.Efficient Computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212dcff5-7b57-432d-a856-c0317f91b01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c419805-5cd1-401e-9be3-7c77fe7e8174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e206d00-de72-4684-a6ef-b4f828c48484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
