{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f3c80a-905b-4873-9845-7281c28c0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Python package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f1744f-5dc5-4566-9db4-ca221dc3331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_file = r'C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_train.csv'\n",
    "test_file = r'C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_test.csv'\n",
    "# Load CSV files into pandas DataFrames\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a59bad-a5dc-4f45-af92-460e4385c6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  hd  cv  vo label\n",
      "0      He most likely converted to islam due to his n...   0   0   0     h\n",
      "1      So Ford lied about being a psychologist. Recor...   0   0   0     h\n",
      "2      Jobs. Education. Ending abuse of Nation. Calif...   0   0   0    nh\n",
      "3      I share a lot of your values, & like many who ...   0   0   0     h\n",
      "4      I am so ready to get back to blogging!  recipe...   0   0   0    nh\n",
      "...                                                  ...  ..  ..  ..   ...\n",
      "22031  I'm a fan of western civilization, and one bed...   0   0   0     h\n",
      "22032  Or ... is she saying that Muslims don't know h...   0   0   0     h\n",
      "22033  Thank you to all my followers that follow me e...   0   0   0     h\n",
      "22034                                  Wednesday music.    0   0   0    nh\n",
      "22035                   This is a really Big Surprise!     0   0   0     h\n",
      "\n",
      "[22036 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05e9197-2e68-4583-92b0-1e10200bec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhargavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b638f9-8b70-46a8-8e94-1fbf5d16d9d4",
   "metadata": {},
   "source": [
    "OneHotEncoding:One hot encoding is a technique that we use to represent categorical variables as numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e79013-2071-4348-8abe-f358e5441222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  hd  cv  vo label\n",
      "0  He most likely converted to islam due to his n...   0   0   0     h\n",
      "1  So Ford lied about being a psychologist. Recor...   0   0   0     h\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22013 entries, 0 to 22035\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    22013 non-null  object\n",
      " 1   hd      22013 non-null  int64 \n",
      " 2   cv      22013 non-null  int64 \n",
      " 3   vo      22013 non-null  int64 \n",
      " 4   label   22013 non-null  object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "print(train_df.head(2), sep = \" \")\n",
    "train_df.info()\n",
    "train_df['text'] = train_df['label'].astype(str)\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(train_df[['label']])\n",
    "# Converting the encoded data into an array\n",
    "encoded_array = encoded_data.toarray()\n",
    "\n",
    "# Print the encoded data (this will show the transformed categorical data)\n",
    "encoded_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89394c-14fd-43ed-8f60-6a132eed1be6",
   "metadata": {},
   "source": [
    "Label Encoding : Label Encoding is a technique that is used to convert categorical columns into numerical ones so that they can be fitted by machine learning models which only take numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31823091-056f-4f03-9432-514e7d85f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHARGAVI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the categorical features\n",
    "encoded_data = label_encoder.fit_transform(train_df[['label']])\n",
    "\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57323369-35d3-4a84-8080-34b80ed7f36d",
   "metadata": {},
   "source": [
    "TF-IDF stands for Term Frequency Inverse Document Frequency of records. It can be defined as the calculation of how relevant a word in a series or corpus is to a text. The meaning increases proportionally to the number of times in the text a word appears but is compensated by the word frequency in the corpus (data-set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf107b93-4b95-49a2-8f1a-bd15e1fde8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2046)\t0.1734177961047654\n",
      "  (0, 2865)\t0.22841937159965145\n",
      "  (0, 2578)\t0.30733769204673606\n",
      "  (0, 4531)\t0.18473798911782097\n",
      "  (0, 2318)\t0.2702851777430834\n",
      "  (0, 1359)\t0.2997086476336335\n",
      "  (0, 2103)\t0.1901106961782535\n",
      "  (0, 2943)\t0.32490862562353595\n",
      "  (0, 465)\t0.21267129484836328\n",
      "  (0, 1748)\t0.12510579599746863\n",
      "  (0, 2319)\t0.310942083693846\n",
      "  (0, 1291)\t0.3916265464291196\n",
      "  (0, 2890)\t0.38341645065029467\n",
      "  (0, 4803)\t0.16319984302244103\n",
      "  (1, 4531)\t0.10000016703543584\n",
      "  (1, 465)\t0.23024138251191123\n",
      "  (1, 4803)\t0.1766827888550042\n",
      "  (1, 4100)\t0.18307056508523645\n",
      "  (1, 1754)\t0.3528720966462922\n",
      "  (1, 2569)\t0.3855430418863006\n",
      "  (1, 87)\t0.1856812604640436\n",
      "  (1, 3619)\t0.37042263776643486\n",
      "  (1, 3915)\t0.3305290824563357\n",
      "  (1, 3980)\t0.23116647920525749\n",
      "  (1, 2395)\t0.18255100990630585\n",
      "  :\t:\n",
      "  (22010, 1735)\t0.16953493028860667\n",
      "  (22010, 1014)\t0.13377703215886275\n",
      "  (22010, 469)\t0.13888417452374757\n",
      "  (22010, 2516)\t0.16442055537006586\n",
      "  (22010, 673)\t0.18965588430824487\n",
      "  (22010, 3178)\t0.14529870883297333\n",
      "  (22010, 2571)\t0.13629569947665954\n",
      "  (22010, 4449)\t0.14756231649844395\n",
      "  (22010, 1732)\t0.1458458101683981\n",
      "  (22010, 2108)\t0.29542157392039464\n",
      "  (22010, 488)\t0.13518526918547383\n",
      "  (22010, 1312)\t0.16653148913790927\n",
      "  (22010, 4701)\t0.14543437315220867\n",
      "  (22010, 169)\t0.15897915591698\n",
      "  (22010, 2324)\t0.2103944799644575\n",
      "  (22010, 2227)\t0.16653148913790927\n",
      "  (22010, 3096)\t0.19386618270983116\n",
      "  (22010, 560)\t0.2103944799644575\n",
      "  (22011, 2902)\t0.6330409866082333\n",
      "  (22011, 4827)\t0.7741182786073938\n",
      "  (22012, 2316)\t0.21409224684837624\n",
      "  (22012, 3602)\t0.4404926351841811\n",
      "  (22012, 4479)\t0.2659560679247386\n",
      "  (22012, 496)\t0.4900711405015668\n",
      "  (22012, 4336)\t0.6702450263667873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_df.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def tfidf_embedding(text):\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    embeddings = vectorizer.fit_transform(text)\n",
    "    return embeddings\n",
    "\n",
    "text = train_df['text'].values\n",
    "embeddings_tfidf = tfidf_embedding(text)\n",
    "print(embeddings_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fe45d81-7e3d-4e58-ac3f-38ed3cacb6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9182\n",
      "Precision: 0.8432\n",
      "Recall: 0.9182\n",
      "F1 Score: 0.8791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BHARGAVI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Step 1: TF-IDF Encoding\n",
    "def tfidf_embedding(text):\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    embeddings = vectorizer.fit_transform(text)\n",
    "    return embeddings\n",
    "\n",
    "text = train_df['text'].values\n",
    "hd = train_df['hd'].values\n",
    "\n",
    "embeddings_tfidf = tfidf_embedding(text)\n",
    "\n",
    "# Step 2: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings_tfidf, hd, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predictions and Evaluation\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92feda-82f7-46ff-8578-fadd8604a15e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
