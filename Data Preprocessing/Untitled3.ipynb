{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3bc9ed2-715c-475d-833f-25b82a5f71ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Train DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22036 entries, 0 to 22035\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    22036 non-null  object\n",
      " 1   hd      22036 non-null  int64 \n",
      " 2   cv      22036 non-null  int64 \n",
      " 3   vo      22036 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 688.8+ KB\n",
      "None\n",
      "                 hd            cv            vo\n",
      "count  22036.000000  22036.000000  22036.000000\n",
      "mean       0.084271      0.005945      0.062579\n",
      "std        0.277800      0.076875      0.242210\n",
      "min        0.000000      0.000000      0.000000\n",
      "25%        0.000000      0.000000      0.000000\n",
      "50%        0.000000      0.000000      0.000000\n",
      "75%        0.000000      0.000000      0.000000\n",
      "max        1.000000      1.000000      1.000000\n",
      "Initial Test DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5510 entries, 0 to 5509\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5510 non-null   object\n",
      " 1   hd      5510 non-null   int64 \n",
      " 2   cv      5510 non-null   int64 \n",
      " 3   vo      5510 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 172.3+ KB\n",
      "None\n",
      "                hd           cv           vo\n",
      "count  5510.000000  5510.000000  5510.000000\n",
      "mean      0.089111     0.004356     0.066969\n",
      "std       0.284929     0.065860     0.249991\n",
      "min       0.000000     0.000000     0.000000\n",
      "25%       0.000000     0.000000     0.000000\n",
      "50%       0.000000     0.000000     0.000000\n",
      "75%       0.000000     0.000000     0.000000\n",
      "max       1.000000     1.000000     1.000000\n",
      "Data after classification:\n",
      "                                                text label\n",
      "0  likely converted islam due nature suitable isl...    nh\n",
      "1  ford lied psychologist record seem indicate st...    nh\n",
      "2               job education ending abuse nation ca    nh\n",
      "3  share lot value like many dont call alt right ...    nh\n",
      "4  ready get back blogging wwwbenbrihousecom reci...    nh\n",
      "                                                text label\n",
      "0  httpswwwyoutubecomwatchvkacwpkaktak talk natur...    nh\n",
      "1  nice tend get tired constant stream ridiculous...    nh\n",
      "2              watch today httpscircumcisionmoviecom    nh\n",
      "3  thinking venue first color layer blocking figu...    nh\n",
      "4  death penalty perpetrator expelling remaining ...    nh\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from scipy import stats\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the TSV files\n",
    "train_file_path = r'F:\\moVies\\Springboard\\data\\ghc_train.tsv'\n",
    "test_file_path = r'F:\\moVies\\Springboard\\data\\ghc_test.tsv'\n",
    "train_df = pd.read_csv(train_file_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_file_path, sep='\\t')\n",
    "\n",
    "# Display initial data summary\n",
    "print(\"Initial Train DataFrame Info:\")\n",
    "print(train_df.info())\n",
    "print(train_df.describe())\n",
    "print(\"Initial Test DataFrame Info:\")\n",
    "print(test_df.info())\n",
    "print(test_df.describe())\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase for consistency\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers to clean the text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove stopwords and lemmatize words to reduce noise\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply text preprocessing\n",
    "train_df['text'] = train_df['text'].apply(preprocess_text)\n",
    "test_df['text'] = test_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Define high-frequency stereotypical words list for hate speech detection\n",
    "stereotypical_words = ['word1', 'word2', 'word3']  # Add actual high-frequency stereotypical words here\n",
    "\n",
    "# Function to detect hate speech based on the provided definitions\n",
    "def detect_hate_speech(text):\n",
    "    # Initialize variables to track hate-based rhetoric\n",
    "    hate_based_rhetoric = {\n",
    "        'HD': False,  # Hate-Based Derogatory Language\n",
    "        'CV': False,  # Calls for Violence\n",
    "        'VO': False,  # Vulgarity/Offensive Language directed at an individual\n",
    "        'SXO': False, # Sexual Orientation\n",
    "        'RAE': False, # Racial or Ethnicity-based\n",
    "        'EX': False   # Expressions of Hate\n",
    "    }\n",
    "    \n",
    "    # Check for high-frequency stereotypical words\n",
    "    for word in stereotypical_words:\n",
    "        if word in text:\n",
    "            hate_based_rhetoric['HD'] = True\n",
    "            \n",
    "    # Check for unnecessary labeling (example: \"a Jew\", \"a Muslim\", etc.)\n",
    "    if re.search(r'\\ba\\s+\\w+\\b', text):\n",
    "        hate_based_rhetoric['HD'] = True\n",
    "    \n",
    "    # Check for other hate-based rhetoric\n",
    "    if re.search(r'\\b(deported|thrown off a roof)\\b', text):\n",
    "        hate_based_rhetoric['CV'] = True\n",
    "    if re.search(r'\\b(muzzie)\\b', text):\n",
    "        hate_based_rhetoric['VO'] = True\n",
    "    if re.search(r'\\b(sexual orientation)\\b', text):\n",
    "        hate_based_rhetoric['SXO'] = True\n",
    "    if re.search(r'\\b(black|Muslim|middle easterner|africans)\\b', text):\n",
    "        hate_based_rhetoric['RAE'] = True\n",
    "    if re.search(r'\\b(hate)\\b', text):\n",
    "        hate_based_rhetoric['EX'] = True\n",
    "    \n",
    "    # Classify the text based on the presence of hate-based rhetoric\n",
    "    if any(hate_based_rhetoric.values()):\n",
    "        return 'h'  # Hate speech detected\n",
    "    else:\n",
    "        return 'nh' # Not hateful\n",
    "\n",
    "# Apply text classification for hate speech detection\n",
    "train_df['label'] = train_df['text'].apply(detect_hate_speech)\n",
    "test_df['label'] = test_df['text'].apply(detect_hate_speech)\n",
    "\n",
    "# Display data after classification\n",
    "print(\"Data after classification:\")\n",
    "print(train_df[['text', 'label']].head())\n",
    "print(test_df[['text', 'label']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
