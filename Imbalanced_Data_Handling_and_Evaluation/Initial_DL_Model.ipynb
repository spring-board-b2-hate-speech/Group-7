{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "010b5d74-eafc-4996-8bc9-843541cd7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_train.csv\"\n",
    "test_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_test.csv\"\n",
    "\n",
    "# Load CSV files into pandas DataFrames\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df=pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63987a2-9f97-4cd2-bd22-8abf7dabdc04",
   "metadata": {},
   "source": [
    "# Preprocessing and Tokenizing for DL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf1059b-80cc-4916-a6f7-861f3c1a1e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to map original labels to binary values\n",
    "def map_labels(df):\n",
    "    label_mapping = {'__label__0': 0, '__label__1': 1}\n",
    "    if 'label' in df.columns:\n",
    "        df['label'] = df['label'].map(label_mapping)\n",
    "    return df\n",
    "\n",
    "# Function to ensure text column is string type and handle missing values\n",
    "def preprocess_text_column(df):\n",
    "    df['text'] = df['text'].fillna('').astype(str)\n",
    "    return df\n",
    "\n",
    "# File paths\n",
    "train_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_train.csv\"\n",
    "test_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_test.csv\"\n",
    "\n",
    "# Load CSV files into pandas DataFrames\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "# Apply functions to preprocess train_df and test_df\n",
    "train_df = map_labels(train_df)\n",
    "test_df = map_labels(test_df)\n",
    "\n",
    "train_df = preprocess_text_column(train_df)\n",
    "test_df = preprocess_text_column(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9a4b1f4-0ed8-40fa-9a3e-2bc1ae28f4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified train_df:\n",
      "                                                text  hd  cv  vo  label\n",
      "0  he most likely converted to islam due to his n...   0   0   0      0\n",
      "1  so ford lied about being a psychologist. recor...   0   0   0      0\n",
      "2     jobs. education. ending abuse of nation. ca43.   0   0   0      0\n",
      "3  i share a lot of your values, & like many who ...   0   0   0      0\n",
      "4  i am so ready to get back to blogging! www.ben...   0   0   0      0\n",
      "\n",
      "Modified test_df:\n",
      "                                                text  hd  cv  vo  label\n",
      "0  https://www.youtube.com/watch?v=kacwpkaktak a ...   0   0   0      0\n",
      "1  very nice! i tend to get tired of the constant...   0   0   0      0\n",
      "2        watch today. https://circumcisionmovie.com/   0   0   0      0\n",
      "3  \" thinking venues \" first color layer blocking...   0   0   0      0\n",
      "4  what about death penalty for perpetrators  and...   0   0   0      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert text column to lowercase\n",
    "def convert_to_lower(df, text):\n",
    "    df[text] = df[text].str.lower()\n",
    "    return df\n",
    "\n",
    "# File paths\n",
    "train_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_train.csv\"\n",
    "test_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_test.csv\"\n",
    "\n",
    "# Load CSV files into pandas DataFrames\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "# Apply convert_to_lower function to 'text' column in train_df and test_df\n",
    "train_df = convert_to_lower(train_df, 'text')\n",
    "test_df = convert_to_lower(test_df, 'text')\n",
    "\n",
    "# Example of using the modified train_df and test_df\n",
    "print(\"Modified train_df:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nModified test_df:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73ad78ac-5264-4176-aac3-d6c6c99f3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Function to tokenize text data\n",
    "def tokenize_texts(train_texts, test_texts, num_words=None):\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "    \n",
    "    X_train_seq = tokenizer.texts_to_sequences(train_texts)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(test_texts)\n",
    "    \n",
    "    return tokenizer, X_train_seq, X_test_seq\n",
    "\n",
    "# Function to pad sequences\n",
    "def pad_sequences_data(X_train_seq, X_test_seq, max_sequence_length):\n",
    "    X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
    "    return X_train_padded, X_test_padded\n",
    "\n",
    "# Function to extract labels\n",
    "def extract_labels(train_data, test_data):\n",
    "    y_train = train_data['label'].values\n",
    "    y_test = test_data['label'].values\n",
    "    return y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96b642c2-5ab1-48d5-88f9-e8a7217441c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_train.csv\"\n",
    "test_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_test.csv\"\n",
    "\n",
    "# Load CSV files into pandas DataFrames\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "# Example usage\n",
    "tokenizer, X_train_seq, X_test_seq = tokenize_texts(train_df['text'], test_df['text'], num_words=5000)\n",
    "X_train_padded, X_test_padded = pad_sequences_data(X_train_seq, X_test_seq, max_sequence_length=100)\n",
    "y_train, y_test = extract_labels(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d33933-332d-466c-afe2-74e8b4819559",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97901cf4-dfe1-4c76-953e-49bda1f0d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "num_words = 5000\n",
    "max_sequence_length = 100\n",
    "\n",
    "tokenizer, X_train_seq, X_test_seq = tokenize_texts(train_df['text'], test_df['text'], num_words=num_words)\n",
    "\n",
    "X_train_padded, X_test_padded = pad_sequences_data(X_train_seq, X_test_seq, max_sequence_length=max_sequence_length)\n",
    "\n",
    "y_train, y_test = extract_labels(train_df, test_df)\n",
    "\n",
    "# Define the LSTM model\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_padded, y_train, epochs=10, batch_size=32, validation_data=(X_test_padded, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "# Predict the labels for test data\n",
    "y_pred_prob = model.predict(X_test_padded)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Print the accuracy and classification report\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22b4e9-3168-4360-9099-4148dbe30de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
