{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0f29f9-0d6a-4c1b-9138-bc890ba197af",
   "metadata": {},
   "source": [
    "MACHINE LEARNING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bb495e-ef31-4dff-9f03-d6a96040b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# File paths\n",
    "train_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_train.csv\"\n",
    "test_file = r\"C:\\Users\\BHARGAVI\\Downloads\\project_data\\ghc_test.csv\"\n",
    "\n",
    "# Load CSV files into pandas DataFrames\n",
    "df = pd.read_csv(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a590a4-77a8-47f4-aca7-0c842d9c4cc8",
   "metadata": {},
   "source": [
    "RANDOM FOREST: Random Forest is a versatile and powerful machine learning algorithm that belongs to the ensemble learning family. It is used for both classification and regression tasks. The name \"Random Forest\" comes from the idea that it builds a forest of decision trees, where each tree is trained independently on a random subset of the data and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cc57fa-bfc7-4f79-890b-2852407c29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming df is the DataFrame containing 'text' and 'label' columns\n",
    "# Step 1: Drop rows with NaN in 'text' column\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "# Step 2: Split the data into X (features) and y (labels)\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Step 3: Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "\n",
    "# Step 4: Fit and transform X (text data) using TfidfVectorizer\n",
    "X = tfidf_vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d2ad3d-3e5a-46f6-ab16-b4c4cabc9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8789896670493685\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3800\n",
      "           1       0.65      0.11      0.19       555\n",
      "\n",
      "    accuracy                           0.88      4355\n",
      "   macro avg       0.77      0.55      0.56      4355\n",
      "weighted avg       0.85      0.88      0.84      4355\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3766   34]\n",
      " [ 493   62]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Initialize and train the RandomForestClassifier model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa8b0d-c7ad-40ca-b1de-e018f592902c",
   "metadata": {},
   "source": [
    "NAIVE BAYES: Multinomial Naive Bayes is a probabilistic classification algorithm that is widely used in natural language processing (NLP) and text classification tasks. It is based on Bayes' theorem with strong (naive) independence assumptions between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44266311-8876-4d67-a391-a2b8ed3b6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB  # Naive Bayes classifier for multinomial models\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming df is your DataFrame containing 'text' and 'label' columns\n",
    "\n",
    "# Step 1: Drop rows with NaN in 'text' column\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "# Step 2: Split the data into X (features) and y (labels)\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Step 3: Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44d420d-f2ba-4c51-8a28-50579ee41031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8780711825487945\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93      3800\n",
      "           1       0.96      0.05      0.09       555\n",
      "\n",
      "    accuracy                           0.88      4355\n",
      "   macro avg       0.92      0.52      0.51      4355\n",
      "weighted avg       0.89      0.88      0.83      4355\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3799    1]\n",
      " [ 530   25]]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Fit and transform X (text data) using TfidfVectorizer\n",
    "X = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Initialize and train the Naive Bayes classifier (MultinomialNB)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8957371-66d9-4866-a36d-d7e14114baf9",
   "metadata": {},
   "source": [
    "KNN: K-Nearest Neighbors (KNN) is a versatile and intuitive machine learning algorithm used for both classification and regression tasks. It is a non-parametric method, meaning it does not make any underlying assumptions about the distribution of the data. Instead, it relies on the proximity of data points in the feature space to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df89b196-d093-4629-b1ea-44623a7fcb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming df is your DataFrame containing 'text' and 'label' columns\n",
    "\n",
    "# Step 1: Drop rows with NaN in 'text' column\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "# Step 2: Split the data into X (features) and y (labels)\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Step 3: Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "\n",
    "# Step 4: Fit and transform X (text data) using TfidfVectorizer\n",
    "X = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Step 5: Convert TF-IDF matrix to dense format for KNN\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7335e0-a172-4fc5-80ac-fe6d3fef0454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8723306544202066\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      3800\n",
      "           1       0.48      0.02      0.04       555\n",
      "\n",
      "    accuracy                           0.87      4355\n",
      "   macro avg       0.68      0.51      0.49      4355\n",
      "weighted avg       0.82      0.87      0.82      4355\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3787   13]\n",
      " [ 543   12]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Initialize and train the KNN classifier\n",
    "# Adjust the number of neighbors (n_neighbors) as needed\n",
    "k = 5  # Example: k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Step 9: Evaluate the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3016277-94b7-4fe0-9409-ea933342319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ee971-e0ea-41f1-b996-f3aeb5cfb49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
